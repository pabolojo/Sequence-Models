{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!cd $HOME/speechBCI/NeuralDecoder && pip install --user -e .\n",
    "#!cd $HOME/speechBCI/LanguageModelDecoder/runtime/server/x86 && python setup.py install\n",
    "#!pip install causal-conv1d\n",
    "#!cd $HOME/mamba && pip install --user -e .\n",
    "#!cd $HOME/neural_seq_decoder && pip install --user -e .\n",
    "#!pip install pytorch-lightning\n",
    "#!pip install tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and Script vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext autoreload\n",
    "#%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from models.datasetLoaders import getDatasetLoaders\n",
    "from models.mamba_phoneme import MambaPhoneme\n",
    "from models.lightning_wrapper import LightningWrapper\n",
    "from mamba_ssm.models.config_mamba import MambaConfig\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "# Mamba Hyperparms\n",
    "args['pppipeline'] = False\n",
    "args['nLayers'] = 1\n",
    "ssm_cfg = {\n",
    "        'd_state'   : 16,\n",
    "        'd_conv'    : 8,\n",
    "        'expand'    : 2,\n",
    "        'dt_rank'   : \"auto\",\n",
    "        'dt_min'    : 0.001,\n",
    "        'dt_max'    : 0.1,\n",
    "        'dt_init'   : \"random\",\n",
    "        'dt_scale'  : 1.0,\n",
    "        'dt_init_floor' : 1e-4,\n",
    "        'conv_bias' : True,\n",
    "        'bias'      : False,\n",
    "        'use_fast_path' : True,  # Fused kernel options\n",
    "        }\n",
    "\n",
    "# Datapaths\n",
    "args['baseDir'] = os.environ['DATA'] + '/willett2023'\n",
    "datsetPath = args['baseDir'] + \"/competitionData/pytorchTFRecords.pkl\"\n",
    "\n",
    "torch.manual_seed(args[\"seed\"])\n",
    "np.random.seed(args[\"seed\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainLoader, testLoader, loadedData = getDatasetLoaders(\n",
    "    datsetPath, args['batchSize']\n",
    ")\n",
    "\n",
    "args['nDays'] = len(loadedData[\"train\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coreModel = MambaPhoneme(\n",
    "    config=MambaConfig(\n",
    "        d_model=args['nInputFeatures'],\n",
    "        n_layer=args['nLayers'],\n",
    "        vocab_size=args['nClasses'],\n",
    "        ssm_cfg=ssm_cfg,\n",
    "        rms_norm=False,\n",
    "        residual_in_fp32=False,\n",
    "        fused_add_norm=False,\n",
    "    ),\n",
    "    device=args['device'],\n",
    "    dtype=torch.float32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(coreModel.modelName)\n",
    "print('Number of parameters: ', sum(p.numel() for p in coreModel.parameters() if p.requires_grad))\n",
    "print('\\n--------------------\\n')\n",
    "print(coreModel)\n",
    "print('\\n--------------------\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seeds and setup output directory\n",
    "timestamp = int(time.time())\n",
    "outputPath = args['baseDir'] + \"/outputs\"\n",
    "logsPath = outputPath + \"/logs\"\n",
    "checkpointPath = outputPath + \"/checkpoints/\" + args['modelName'] + \"_\" + str(timestamp)\n",
    "\n",
    "os.makedirs(outputPath, exist_ok=True)\n",
    "\n",
    "# Define the logger\n",
    "logger = TensorBoardLogger(logsPath, name=coreModel.modelName)\n",
    "\n",
    "# Define the checkpoint callback\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=checkpointPath,\n",
    "    monitor='val_loss',\n",
    "    filename='{epoch:02d}-{val_loss:.2f}-{avg_val_cer:.2f}',\n",
    "    save_last=False,\n",
    "    save_top_k=2,\n",
    "    verbose=True,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "# Define early stopping callback\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0.00,\n",
    "    patience=20,\n",
    "    verbose=False,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "callbacks = [checkpoint_callback, early_stop_callback]\n",
    "\n",
    "loss_ctc = torch.nn.CTCLoss(blank=0, reduction=\"mean\", zero_infinity=True)\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    coreModel.parameters(),\n",
    "    lr=args[\"lrStart\"],\n",
    "    betas=(0.9, 0.999),\n",
    "    eps=0.1,\n",
    "    weight_decay=args[\"l2_decay\"],\n",
    ")\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.LinearLR(\n",
    "    optimizer,\n",
    "    start_factor=1.0,\n",
    "    end_factor=args[\"lrEnd\"] / args[\"lrStart\"],\n",
    "    total_iters=args[\"nEpochs\"],\n",
    ")\n",
    "\n",
    "# Training\n",
    "model = LightningWrapper(coreModel, loss_ctc, optimizer, args, scheduler, willetts_preprocessing_pipeline = args['pppipeline'])\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(\n",
    "    max_epochs=args[\"nEpochs\"],\n",
    "    log_every_n_steps=100,\n",
    "    check_val_every_n_epoch=1,\n",
    "    logger=logger,\n",
    "    callbacks=callbacks,\n",
    "    enable_progress_bar=False\n",
    ")\n",
    "\n",
    "trainer.fit(model, trainLoader, val_dataloaders=testLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
